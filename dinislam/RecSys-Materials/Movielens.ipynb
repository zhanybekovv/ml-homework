{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collobarative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very useful and easy to use library, that you can use to realize recommender systems algorithms, **surpise**.\n",
    "\n",
    "First of all lets talk about dataset type, loading a rating dataset can be done either from a file(e.g. a csv file) or from a pandas dataframe. Either way, you will need to define  a **Reader** object for Surprise to able to parse the file or the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.reader.Reader at 0x116a479b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(df[['userId','movieId','rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x11683f5f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9061  0.8989  0.9003  0.9018  0.0031  \n",
      "MAE (testset)     0.6986  0.6937  0.6943  0.6955  0.0022  \n",
      "Fit time          3.28    3.31    3.19    3.26    0.05    \n",
      "Test time         0.27    0.24    0.23    0.25    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.90611217, 0.89893585, 0.90032118]),\n",
       " 'test_mae': array([0.69856586, 0.69366   , 0.69426756]),\n",
       " 'fit_time': (3.2814078330993652, 3.307137966156006, 3.1912550926208496),\n",
       " 'test_time': (0.2697010040283203, 0.23993492126464844, 0.2340531349182129)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo,data,measures=['RMSE','MAE'],cv=3,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if u dont use run full a full cross validation process, you can just use the train test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset,testset = train_test_split(data,test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8929756873814392"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example where we use a classical K-fold cross-validation procedure with 3 splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9044\n",
      "RMSE: 0.9060\n",
      "RMSE: 0.8997\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  tune parameters with grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_epochs':[5,10],\n",
    "    'lr_all':[0.002,0.005],\n",
    "    'reg_all':[0.4,0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD,param_grid,measures=['rmse','mae'],cv=3)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141861846996203"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4},\n",
       " 'mae': {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There we are gonna to build recommender system with Surprise library, and will check some of the metrics, which will help us to the better data understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens:\n",
    "\n",
    "    movieID_to_name = {}\n",
    "    name_to_movieID = {}\n",
    "    ratingsPath = \"/home/predator/Desktop/Education/RecSys-Materials/ml-latest-small/ratings.csv\"\n",
    "    moviesPath   = \"/home/predator/Desktop/Education/RecSys-Materials/ml-latest-small/movies.csv\"\n",
    "\n",
    "    def loadMovieLensLatestSmall(self):\n",
    "\n",
    "        # Look for files relative to the directory we are running from\n",
    "        os.chdir(os.path.dirname(sys.argv[0]))\n",
    "\n",
    "        ratingsDataset = 0\n",
    "        self.movieID_to_name = {}\n",
    "        self.name_to_movieID = {}\n",
    "\n",
    "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "\n",
    "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
    "\n",
    "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "                movieReader = csv.reader(csvfile)\n",
    "                next(movieReader)  #Skip header line\n",
    "                for row in movieReader:\n",
    "                    movieID = int(row[0])\n",
    "                    movieName = row[1]\n",
    "                    self.movieID_to_name[movieID] = movieName\n",
    "                    self.name_to_movieID[movieName] = movieID\n",
    "\n",
    "        return ratingsDataset\n",
    "\n",
    "    def getUserRatings(self, user):\n",
    "        userRatings = []\n",
    "        hitUser = False\n",
    "        with open(self.ratingsPath, newline='') as csvfile:\n",
    "            ratingReader = csv.reader(csvfile)\n",
    "            next(ratingReader)\n",
    "            for row in ratingReader:\n",
    "                userID = int(row[0])\n",
    "                if (user == userID):\n",
    "                    movieID = int(row[1])\n",
    "                    rating = float(row[2])\n",
    "                    userRatings.append((movieID, rating))\n",
    "                    hitUser = True\n",
    "                if (hitUser and (user != userID)):\n",
    "                    break\n",
    "\n",
    "        return userRatings\n",
    "\n",
    "    def getPopularityRanks(self):\n",
    "        ratings = defaultdict(int)\n",
    "        rankings = defaultdict(int)\n",
    "        with open(self.ratingsPath, newline='') as csvfile:\n",
    "            ratingReader = csv.reader(csvfile)\n",
    "            next(ratingReader)\n",
    "            for row in ratingReader:\n",
    "                movieID = int(row[1])\n",
    "                ratings[movieID] += 1\n",
    "        rank = 1\n",
    "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "            rankings[movieID] = rank\n",
    "            rank += 1\n",
    "        return rankings\n",
    "    \n",
    "    def getGenres(self):\n",
    "        genres = defaultdict(list)\n",
    "        genreIDs = {}\n",
    "        maxGenreID = 0\n",
    "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "            movieReader = csv.reader(csvfile)\n",
    "            next(movieReader)  #Skip header line\n",
    "            for row in movieReader:\n",
    "                movieID = int(row[0])\n",
    "                genreList = row[2].split('|')\n",
    "                genreIDList = []\n",
    "                for genre in genreList:\n",
    "                    if genre in genreIDs:\n",
    "                        genreID = genreIDs[genre]\n",
    "                    else:\n",
    "                        genreID = maxGenreID\n",
    "                        genreIDs[genre] = genreID\n",
    "                        maxGenreID += 1\n",
    "                    genreIDList.append(genreID)\n",
    "                genres[movieID] = genreIDList\n",
    "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
    "        for (movieID, genreIDList) in genres.items():\n",
    "            bitfield = [0] * maxGenreID\n",
    "            for genreID in genreIDList:\n",
    "                bitfield[genreID] = 1\n",
    "            genres[movieID] = bitfield            \n",
    "        \n",
    "        return genres\n",
    "    \n",
    "    def getYears(self):\n",
    "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
    "        years = defaultdict(int)\n",
    "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "            movieReader = csv.reader(csvfile)\n",
    "            next(movieReader)\n",
    "            for row in movieReader:\n",
    "                movieID = int(row[0])\n",
    "                title = row[1]\n",
    "                m = p.search(title)\n",
    "                year = m.group(1)\n",
    "                if year:\n",
    "                    years[movieID] = int(year)\n",
    "        return years\n",
    "    \n",
    "    def getMiseEnScene(self):\n",
    "        mes = defaultdict(list)\n",
    "        with open(\"LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
    "            mesReader = csv.reader(csvfile)\n",
    "            next(mesReader)\n",
    "            for row in mesReader:\n",
    "                movieID = int(row[0])\n",
    "                avgShotLength = float(row[1])\n",
    "                meanColorVariance = float(row[2])\n",
    "                stddevColorVariance = float(row[3])\n",
    "                meanMotion = float(row[4])\n",
    "                stddevMotion = float(row[5])\n",
    "                meanLightingKey = float(row[6])\n",
    "                numShots = float(row[7])\n",
    "                mes[movieID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
    "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
    "        return mes\n",
    "    \n",
    "    def getMovieName(self, movieID):\n",
    "        if movieID in self.movieID_to_name:\n",
    "            return self.movieID_to_name[movieID]\n",
    "        else:\n",
    "            return \"\"\n",
    "        \n",
    "    def getMovieID(self, movieName):\n",
    "        if movieName in self.name_to_movieID:\n",
    "            return self.name_to_movieID[movieName]\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "User  85  loved these movies:\n",
      "Jumanji (1995)\n",
      "GoldenEye (1995)\n",
      "Braveheart (1995)\n",
      "Jerky Boys, The (1995)\n",
      "LÃ©on: The Professional (a.k.a. The Professional) (LÃ©on) (1994)\n",
      "Pulp Fiction (1994)\n",
      "Stargate (1994)\n",
      "Shawshank Redemption, The (1994)\n",
      "Star Trek: Generations (1994)\n",
      "Clear and Present Danger (1994)\n",
      "Speed (1994)\n",
      "True Lies (1994)\n",
      "Fugitive, The (1993)\n",
      "Jurassic Park (1993)\n",
      "Terminator 2: Judgment Day (1991)\n",
      "Mission: Impossible (1996)\n",
      "Rock, The (1996)\n",
      "\n",
      "...and didn't like these movies:\n",
      "Grumpier Old Men (1995)\n",
      "Mortal Kombat (1995)\n",
      "Postman, The (Postino, Il) (1994)\n",
      "Casper (1995)\n",
      "Lord of Illusions (1995)\n",
      "Mighty Morphin Power Rangers: The Movie (1995)\n",
      "Prophecy, The (1995)\n",
      "Dolores Claiborne (1995)\n",
      "Heavenly Creatures (1994)\n",
      "Little Women (1994)\n",
      "Miracle on 34th Street (1994)\n",
      "Nell (1994)\n",
      "Poison Ivy II (1996)\n",
      "Tank Girl (1995)\n",
      "While You Were Sleeping (1995)\n",
      "Wes Craven's New Nightmare (Nightmare on Elm Street Part 7: Freddy's Finale, A) (1994)\n",
      "Naked Gun 33 1/3: The Final Insult (1994)\n",
      "Richie Rich (1994)\n",
      "Beverly Hills Cop III (1994)\n",
      "Philadelphia (1993)\n",
      "Schindler's List (1993)\n",
      "Super Mario Bros. (1993)\n",
      "Nightmare Before Christmas, The (1993)\n",
      "Snow White and the Seven Dwarfs (1937)\n",
      "Operation Dumbo Drop (1995)\n",
      "Oliver & Company (1988)\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Lord of the Rings: The Two Towers, The (2002)\n",
      "North by Northwest (1959)\n",
      "Empire of the Sun (1987)\n",
      "Rear Window (1954)\n",
      "Gladiator (1992)\n",
      "Paperman (2012)\n",
      "Matrix, The (1999)\n",
      "American Beauty (1999)\n",
      "Pianist, The (2002)\n",
      "Fight Club (1999)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def BuildAntiTestSetForUser(testSubject, trainset):\n",
    "    fill = trainset.global_mean\n",
    "\n",
    "    anti_testset = []\n",
    "    \n",
    "    u = trainset.to_inner_uid(str(testSubject))\n",
    "    \n",
    "    user_items = set([j for (j, _) in trainset.ur[u]])\n",
    "    anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
    "                             i in trainset.all_items() if\n",
    "                             i not in user_items]\n",
    "    return anti_testset\n",
    "\n",
    "# Pick an arbitrary test subject\n",
    "testSubject = 85\n",
    "\n",
    "ml = MovieLens()\n",
    "\n",
    "print(\"Loading movie ratings...\")\n",
    "data = ml.loadMovieLensLatestSmall()\n",
    "\n",
    "userRatings = ml.getUserRatings(testSubject)\n",
    "loved = []\n",
    "hated = []\n",
    "for ratings in userRatings:\n",
    "    if (float(ratings[1]) > 4.0):\n",
    "        loved.append(ratings)\n",
    "    if (float(ratings[1]) < 3.0):\n",
    "        hated.append(ratings)\n",
    "\n",
    "print(\"\\nUser \", testSubject, \" loved these movies:\")\n",
    "for ratings in loved:\n",
    "    print(ml.getMovieName(ratings[0]))\n",
    "print(\"\\n...and didn't like these movies:\")\n",
    "for ratings in hated:\n",
    "    print(ml.getMovieName(ratings[0]))\n",
    "\n",
    "print(\"\\nBuilding recommendation model...\")\n",
    "trainSet = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainSet)\n",
    "\n",
    "print(\"Computing recommendations...\")\n",
    "testSet = BuildAntiTestSetForUser(testSubject, trainSet)\n",
    "predictions = algo.test(testSet)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "print (\"\\nWe recommend:\")\n",
    "for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "    intMovieID = int(movieID)\n",
    "    recommendations.append((intMovieID, estimatedRating))\n",
    "\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for ratings in recommendations[:10]:\n",
    "    print(ml.getMovieName(ratings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderMetrics:\n",
    "    # Mean absoulte error\n",
    "    def MAE(predictions):\n",
    "        return accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    # root mean score error\n",
    "    def RMSE(predictions):\n",
    "        return accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    # just gives you topN recommendations per user, with ability to change threshold\n",
    "    def GetTopN(predictions, n=10, minimumRating=4.0):\n",
    "        topN = defaultdict(list)\n",
    "\n",
    "\n",
    "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "            if (estimatedRating >= minimumRating):\n",
    "                topN[int(userID)].append((int(movieID), estimatedRating))\n",
    "\n",
    "        for userID, ratings in topN.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            topN[int(userID)] = ratings[:n]\n",
    "\n",
    "        return topN\n",
    "\n",
    "    # gives you hit rate\n",
    "    def HitRate(topNPredicted, leftOutPredictions):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "\n",
    "        # For each left-out rating\n",
    "        for leftOut in leftOutPredictions:\n",
    "            userID = leftOut[0]\n",
    "            leftOutMovieID = leftOut[1]\n",
    "            # Is it in the predicted top 10 for this user?\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutMovieID) == int(movieID)):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        return hits/total\n",
    "    \n",
    "    \n",
    "    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Only look at ability to recommend things the users actually liked...\n",
    "            if (actualRating >= ratingCutoff):\n",
    "                # Is it in the predicted top 10 for this user?\n",
    "                hit = False\n",
    "                for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                    if (int(leftOutMovieID) == movieID):\n",
    "                        hit = True\n",
    "                        break\n",
    "                if (hit) :\n",
    "                    hits += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        return hits/total\n",
    "\n",
    "    def RatingHitRate(topNPredicted, leftOutPredictions):\n",
    "        hits = defaultdict(float)\n",
    "        total = defaultdict(float)\n",
    "\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Is it in the predicted top N for this user?\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutMovieID) == movieID):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits[actualRating] += 1\n",
    "\n",
    "            total[actualRating] += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        for rating in sorted(hits.keys()):\n",
    "            print (rating, hits[rating] / total[rating])\n",
    "\n",
    "    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
    "        summation = 0\n",
    "        total = 0\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Is it in the predicted top N for this user?\n",
    "            hitRank = 0\n",
    "            rank = 0\n",
    "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
    "                rank = rank + 1\n",
    "                if (int(leftOutMovieID) == movieID):\n",
    "                    hitRank = rank\n",
    "                    break\n",
    "            if (hitRank > 0) :\n",
    "                summation += 1.0 / hitRank\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        return summation / total\n",
    "\n",
    "    # What percentage of users have at least one \"good\" recommendation\n",
    "    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
    "        hits = 0\n",
    "        for userID in topNPredicted.keys():\n",
    "            hit = False\n",
    "            for movieID, predictedRating in topNPredicted[userID]:\n",
    "                if (predictedRating >= ratingThreshold):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit):\n",
    "                hits += 1\n",
    "\n",
    "        return hits / numUsers\n",
    "\n",
    "    def Diversity(topNPredicted, simsAlgo):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        simsMatrix = simsAlgo.compute_similarities()\n",
    "        for userID in topNPredicted.keys():\n",
    "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
    "            for pair in pairs:\n",
    "                movie1 = pair[0][0]\n",
    "                movie2 = pair[1][0]\n",
    "                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
    "                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
    "                similarity = simsMatrix[innerID1][innerID2]\n",
    "                total += similarity\n",
    "                n += 1\n",
    "\n",
    "        S = total / n\n",
    "        return (1-S)\n",
    "\n",
    "    def Novelty(topNPredicted, rankings):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        for userID in topNPredicted.keys():\n",
    "            for rating in topNPredicted[userID]:\n",
    "                movieID = rating[0]\n",
    "                rank = rankings[movieID]\n",
    "                total += rank\n",
    "                n += 1\n",
    "        return total / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "#from RecommenderMetrics import RecommenderMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "\n",
      "Computing item similarities so we can measure diversity later...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Building recommendation model...\n",
      "\n",
      "Computing recommendations...\n",
      "\n",
      "Evaluating accuracy of model...\n",
      "RMSE:  0.9033701087151801\n",
      "MAE:  0.6977882196132263\n",
      "\n",
      "Evaluating top-10 recommendations...\n",
      "Computing recommendations with leave-one-out...\n",
      "Predict ratings for left-out set...\n",
      "Predict all missing ratings...\n",
      "Compute top 10 recs per user...\n",
      "\n",
      "Hit Rate:  0.029806259314456036\n",
      "\n",
      "rHR (Hit Rate by Rating value): \n",
      "3.5 0.017241379310344827\n",
      "4.0 0.0425531914893617\n",
      "4.5 0.020833333333333332\n",
      "5.0 0.06802721088435375\n",
      "\n",
      "cHR (Cumulative Hit Rate, rating >= 4):  0.04960835509138381\n",
      "\n",
      "ARHR (Average Reciprocal Hit Rank):  0.0111560570576964\n",
      "\n",
      "Computing complete recommendations, no hold outs...\n",
      "\n",
      "User coverage:  0.9552906110283159\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Diversity:  0.9665208258150911\n",
      "\n",
      "Novelty (average popularity rank):  491.5767777960256\n"
     ]
    }
   ],
   "source": [
    "ml = MovieLens()\n",
    "\n",
    "print(\"Loading movie ratings...\")\n",
    "data = ml.loadMovieLensLatestSmall()\n",
    "\n",
    "print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
    "rankings = ml.getPopularityRanks()\n",
    "\n",
    "print(\"\\nComputing item similarities so we can measure diversity later...\")\n",
    "fullTrainSet = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "simsAlgo = KNNBaseline(sim_options=sim_options)\n",
    "simsAlgo.fit(fullTrainSet)\n",
    "\n",
    "print(\"\\nBuilding recommendation model...\")\n",
    "trainSet, testSet = train_test_split(data, test_size=.25, random_state=1)\n",
    "\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(trainSet)\n",
    "\n",
    "print(\"\\nComputing recommendations...\")\n",
    "predictions = algo.test(testSet)\n",
    "\n",
    "print(\"\\nEvaluating accuracy of model...\")\n",
    "print(\"RMSE: \", RecommenderMetrics.RMSE(predictions))\n",
    "print(\"MAE: \", RecommenderMetrics.MAE(predictions))\n",
    "\n",
    "print(\"\\nEvaluating top-10 recommendations...\")\n",
    "\n",
    "# Set aside one rating per user for testing\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    print(\"Computing recommendations with leave-one-out...\")\n",
    "\n",
    "    # Train model without left-out ratings\n",
    "    algo.fit(trainSet)\n",
    "\n",
    "    # Predicts ratings for left-out ratings only\n",
    "    print(\"Predict ratings for left-out set...\")\n",
    "    leftOutPredictions = algo.test(testSet)\n",
    "\n",
    "    # Build predictions for all ratings not in the training set\n",
    "    print(\"Predict all missing ratings...\")\n",
    "    bigTestSet = trainSet.build_anti_testset()\n",
    "    allPredictions = algo.test(bigTestSet)\n",
    "\n",
    "    # Compute top 10 recs for each user\n",
    "    print(\"Compute top 10 recs per user...\")\n",
    "    topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n=10)\n",
    "\n",
    "    # See how often we recommended a movie the user actually rated\n",
    "    print(\"\\nHit Rate: \", RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions))\n",
    "\n",
    "    # Break down hit rate by rating value\n",
    "    print(\"\\nrHR (Hit Rate by Rating value): \")\n",
    "    RecommenderMetrics.RatingHitRate(topNPredicted, leftOutPredictions)\n",
    "\n",
    "    # See how often we recommended a movie the user actually liked\n",
    "    print(\"\\ncHR (Cumulative Hit Rate, rating >= 4): \", RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions, 4.0))\n",
    "\n",
    "    # Compute ARHR\n",
    "    print(\"\\nARHR (Average Reciprocal Hit Rank): \", RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions))\n",
    "\n",
    "print(\"\\nComputing complete recommendations, no hold outs...\")\n",
    "algo.fit(fullTrainSet)\n",
    "bigTestSet = fullTrainSet.build_anti_testset()\n",
    "allPredictions = algo.test(bigTestSet)\n",
    "topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n=10)\n",
    "\n",
    "# Print user coverage with a minimum predicted rating of 4.0:\n",
    "print(\"\\nUser coverage: \", RecommenderMetrics.UserCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0))\n",
    "\n",
    "# Measure diversity of recommendations:\n",
    "print(\"\\nDiversity: \", RecommenderMetrics.Diversity(topNPredicted, simsAlgo))\n",
    "\n",
    "# Measure novelty (average popularity rank of recommendations):\n",
    "print(\"\\nNovelty (average popularity rank): \", RecommenderMetrics.Novelty(topNPredicted, rankings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
